{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59208315",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "import uuid\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime, timezone\n",
    "import shutil\n",
    "\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "from pyspark.sql.types import StructType, StringType, DoubleType, TimestampType\n",
    "import pyspark.sql.functions as F\n",
    "\n",
    "PROJECT_PATH = Path.cwd().parent\n",
    "DATA_DIR = '.data'\n",
    "DATA_PATH = PROJECT_PATH / DATA_DIR\n",
    "DATA_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "output_folder = str(DATA_PATH)\n",
    "checkpoint_path = str(Path.cwd() / 'checkpoint')\n",
    "shutil.rmtree(checkpoint_path, True)\n",
    "output_path = str(Path.cwd() / 'test.csv')\n",
    "shutil.rmtree(output_path, True)\n",
    "\n",
    "file_schema = StructType() \\\n",
    "    .add('id', StringType()) \\\n",
    "    .add('temperature', DoubleType()) \\\n",
    "    .add('timestamp', TimestampType())\n",
    "\n",
    "schema_name = 'dp700_e011'\n",
    "table_name = 'temperature_stream'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9d529105",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "spark = SparkSession.builder.appName('test').master('local[*]').getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e0459b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spark.sql(f'CREATE SCHEMA IF NOT EXISTS {schema_name}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "75412596",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/08/21 18:06:02 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    }
   ],
   "source": [
    "raw_stream_df = spark.readStream \\\n",
    "    .schema(file_schema) \\\n",
    "    .option('maxFilesPerTrigger', 1) \\\n",
    "    .json(output_folder)\n",
    "\n",
    "transformed_stream_df = raw_stream_df \\\n",
    "    .withColumn('processed_timestamp',\n",
    "        F.current_timestamp())\n",
    "\n",
    "delta_stream = transformed_stream_df.writeStream \\\n",
    "    .format('memory') \\\n",
    "    .queryName(\"filtered\") \\\n",
    "    .outputMode('append') \\\n",
    "    .option('checkpointLocation', checkpoint_path) \\\n",
    "    .start(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "551c7275",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_stream.processAllAvailable()\n",
    "\n",
    "\n",
    "# while delta_stream.isActive:\n",
    "#     print(delta_stream.status)\n",
    "#     print(delta_stream.lastProgress)\n",
    "#     time.sleep(5)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84afa5d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------------+-----------+--------------------------+-----------------------+\n",
      "|id                                  |temperature|timestamp                 |processed_timestamp    |\n",
      "+------------------------------------+-----------+--------------------------+-----------------------+\n",
      "|69f36f78-8be6-4411-8676-224ce615d58e|18.97      |2025-08-21 18:05:11.485252|2025-08-21 18:06:02.39 |\n",
      "|f7fefba8-23a3-4576-8ef1-d929435aae4e|21.57      |2025-08-21 18:05:16.487076|2025-08-21 18:06:02.495|\n",
      "|bc63ba8c-9b62-4ceb-a6c7-ae9428a16634|25.47      |2025-08-21 18:05:21.499135|2025-08-21 18:06:02.585|\n",
      "|1a5ea9b5-c8b0-40d1-a284-574565065fb0|25.47      |2025-08-21 18:05:26.50459 |2025-08-21 18:06:02.671|\n",
      "|860ec31e-8443-48c7-b739-c1e67a110541|22.39      |2025-08-21 18:05:31.509125|2025-08-21 18:06:02.755|\n",
      "|7aa49303-59e2-4142-a3c8-9c2fdefa9dac|20.97      |2025-08-21 18:05:36.513156|2025-08-21 18:06:02.866|\n",
      "|bc602119-4d5e-4cce-a477-e09a5ec3aedc|19.87      |2025-08-21 18:05:41.51665 |2025-08-21 18:06:02.942|\n",
      "|79b016db-26f1-4044-9a39-f4a9e1c7da6d|27.84      |2025-08-21 18:05:46.523492|2025-08-21 18:06:03.029|\n",
      "|66e54fe6-5659-4030-88f5-1311d87820b1|28.21      |2025-08-21 18:05:51.525451|2025-08-21 18:06:03.124|\n",
      "|93ac07ac-9e89-4edd-9efc-8d852161200f|24.69      |2025-08-21 18:05:56.533402|2025-08-21 18:06:03.201|\n",
      "+------------------------------------+-----------+--------------------------+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# df = spark.sql(f'SELECT * FROM {schema_name}.{table_name}')\n",
    "df = spark.sql(f'SELECT * FROM filtered')\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7b99c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_stream.stop()\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aleksei-partanen-spark-structured-streaming",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
